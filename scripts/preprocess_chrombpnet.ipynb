{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b106a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64ef08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import, names of train, test, val\n",
    "import numpy as np\n",
    "import pysam\n",
    "from tqdm.notebook import tqdm\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "basedir = '/data/leslie/shared/ASA/'\n",
    "aligndir = f'{basedir}pseudodiploid/atac/'\n",
    "ctype = 'cd8'\n",
    "ident = '_vi_chrom'\n",
    "\n",
    "datadir = f'{basedir}mouseASA/{ctype}/cast/data/'\n",
    "chroms = list(range(1,20))\n",
    "\n",
    "reps = ['r1','r2','r3','r4','r5']\n",
    "seqlen = 2114                         # region around summit for sequence\n",
    "outlen = 1000                        # region around summit for coverage\n",
    "save = True                          # failsafe to prevent unwanted overwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87b9ec5",
   "metadata": {},
   "source": [
    "# Preprocessing of Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec872134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get replicate counts\n",
    "from utils import get_shifts, one_hot, get_neg_summits\n",
    "\n",
    "N = []\n",
    "for rep in reps:\n",
    "    bamfile = aligndir+ctype+'/'+rep+'.combined.rmDup.Aligned.sortedByCoord.out.bam'\n",
    "    bamf = pysam.AlignmentFile(bamfile, \"rb\")\n",
    "    N.append( sum([bamf.get_index_statistics()[i][1] for i in range(len(chroms))]) )\n",
    "    bamf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d347a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get peak and uneg summits\n",
    "if ident[:3]=='_vi':\n",
    "    summits = pd.read_csv(aligndir+'cd8_old/yi_cd8_peaks_33143.csv',sep=',',index_col=0)\n",
    "    summits['start'] += seqlen//2\n",
    "    summits = summits.iloc[:,1:3]\n",
    "    summits.columns = range(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d49c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the list of summits in train and val by randomly adding seqlen//3 shifts (100bp)\n",
    "augment = True      # for augmentation of data by shifting sequence window\n",
    "\n",
    "if augment:\n",
    "    ident += '_aug'\n",
    "    frac = 1.0\n",
    "    # Randomly shift all the summits by + or - seqlen//3\n",
    "    summits_aug = summits.copy()\n",
    "    shifts = seqlen//3 * rng.choice([-1,1], len(summits_aug), replace=True)\n",
    "    summits_aug[1] += shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e802a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate x, y and p (profile)\n",
    "import gzip\n",
    "from Bio import SeqIO\n",
    "from bisect import bisect\n",
    "\n",
    "bamfile = aligndir+ctype+'/'+reps[0]+'.combined.rmDup.Aligned.sortedByCoord.out.bam'\n",
    "bamf = pysam.AlignmentFile(bamfile, \"rb\")\n",
    "\n",
    "def neg_summit_generator(c, chromsummits, seqlen, bamf):\n",
    "    neg_summits = np.empty(0, dtype=np.int64)\n",
    "    seed=0\n",
    "    while len(neg_summits)<len(chromsummits):     # get neg summits and only keep low coverage ones (<5)\n",
    "        temp = get_neg_summits(chromsummits, len(chromsummits)-len(neg_summits), len(seq_b6), seed)\n",
    "        idx = np.where(np.array([bamf.count(str(c),i-seqlen//2,i+seqlen//2) for i in temp]) < 20)[0]\n",
    "        temp = temp[idx]\n",
    "        neg_summits = np.concatenate((neg_summits, temp))\n",
    "        seed+=1\n",
    "    neg_summits = np.sort(neg_summits)\n",
    "    return neg_summits\n",
    "\n",
    "def parse_bed(path):\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "    df = df.loc[np.where(df[0].isin(list(range(1,20))))[0],:].reset_index(drop=True)\n",
    "    df[0] = df[0].astype(int)\n",
    "    temp = np.empty(len(df), dtype=int)\n",
    "    idx = np.where(df[5]=='+')[0]\n",
    "    temp[idx] = df[1][idx]\n",
    "    idx = np.where(df[5]=='-')[0]\n",
    "    temp[idx] = df[2][idx] - 1        # Correct for 1-based indexing in third BED column\n",
    "    df[1]=temp\n",
    "    df = df.drop([2,3,4,5], axis=1)\n",
    "    return df\n",
    "\n",
    "gen_b6 = SeqIO.index(f'{basedir}pseudodiploid/gen/b6.fa', 'fasta')\n",
    "gen_cast = SeqIO.index(f'{basedir}pseudodiploid/gen/cast.fa', 'fasta')\n",
    "\n",
    "modfile = f'{basedir}pseudodiploid/gen/cast.mod'\n",
    "with gzip.open(modfile,'rt') as f:\n",
    "    mods = f.read().split('\\n')\n",
    "    mods = [x for x in mods if not (x.startswith('s') or x.startswith('#'))][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf97171e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10e5b819fdd4929990e831731a69429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8439eb19989e4a738d1dd99ac26a6d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d186291bca3f4fef8a312780902e6f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abd33b7d38a47a1940697d12de5d8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b8743323104cd98e4f0b87640fc14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n",
      "/scratch/lsftmp/3870496.tmpdir/ipykernel_1362/559853194.py:22: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep='\\t', header=None)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71c6998d0e445d6a80e8f87f5cdcc19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = dict()\n",
    "p = dict()\n",
    "neg_summits = dict()\n",
    "\n",
    "for cnt,rep in enumerate(tqdm(reps)):\n",
    "    temp1 = parse_bed(f'{datadir}bed/{rep}_b6.bed.gz')\n",
    "    temp2 = parse_bed(f'{datadir}bed/{rep}_cast.bed.gz')\n",
    "    temp3 = parse_bed(f'{datadir}bed/{rep}_both.bed.gz')\n",
    "\n",
    "    for c in tqdm(chroms):         # for each chr (in first rep get all the x seqs)\n",
    "        for allele in ['b6','ca']:\n",
    "            for label in ['','_unegs','_aug']:\n",
    "                p[rep+'_chr'+str(c)+'_'+allele+label] = []\n",
    "                if cnt==0:\n",
    "                    x['chr'+str(c)+'_'+allele+label] = []\n",
    "        \n",
    "        \n",
    "        chromsummits = summits.iloc[np.where(summits[0]==c)[0],1]     # slice out the relevant chromosome summits\n",
    "        augsummits = summits_aug.iloc[np.where(summits_aug[0]==c)[0],1]\n",
    "        # For sequence (x)\n",
    "        if cnt==0:\n",
    "            seq_b6 = ''.join(gen_b6.get_raw(str(c)).decode().split('\\n')[1:])\n",
    "            seq_cast = ''.join(gen_cast.get_raw(str(c)).decode().split('\\n')[1:])\n",
    "            # get relevant b6 & ca genomic seqs\n",
    "            cast_shifts = get_shifts(chromsummits, mods, c)\n",
    "            x['chr'+str(c)+'_b6'] += [seq_b6[i-seqlen//2:i+seqlen//2] for i in chromsummits]\n",
    "            x['chr'+str(c)+'_ca'] += [seq_cast[i+j-seqlen//2:i+j+seqlen//2] for i,j in zip(chromsummits,cast_shifts)]\n",
    "            # get relevant uneg genomic seqs\n",
    "            neg_summits[c] = neg_summit_generator(c, chromsummits, seqlen, bamf)\n",
    "            cast_shifts = get_shifts(neg_summits[c], mods, c)\n",
    "            x['chr'+str(c)+'_b6_unegs'] += [seq_b6[i-seqlen//2:i+seqlen//2] for i in neg_summits[c]]\n",
    "            x['chr'+str(c)+'_ca_unegs'] += [seq_cast[i+j-seqlen//2:i+j+seqlen//2] for i,j in zip(neg_summits[c],cast_shifts)]\n",
    "            # get relevant aug genomic seqs\n",
    "            cast_shifts = get_shifts(augsummits, mods, c)\n",
    "            x['chr'+str(c)+'_b6_aug'] += [seq_b6[i-seqlen//2:i+seqlen//2] for i in augsummits]\n",
    "            x['chr'+str(c)+'_ca_aug'] += [seq_cast[i+j-seqlen//2:i+j+seqlen//2] for i,j in zip(augsummits,cast_shifts)]\n",
    "            for allele in ['b6','ca']:\n",
    "                for label in ['','_unegs','_aug']:\n",
    "                    x['chr'+str(c)+'_'+allele+label] = one_hot(x['chr'+str(c)+'_'+allele+label])         # convert string of nucleotides to one-hot representation\n",
    "\n",
    "        \n",
    "        # For profile (p)\n",
    "        temp1_chrom = np.array(temp1.iloc[np.where(temp1[0]==c)][1])         # slice each BED dataframe of insertion sites\n",
    "        temp2_chrom = np.array(temp2.iloc[np.where(temp2[0]==c)][1])\n",
    "        temp3_chrom = np.array(temp3.iloc[np.where(temp3[0]==c)][1])\n",
    "\n",
    "        p_b6 = []\n",
    "        p_cast = []\n",
    "        for i in chromsummits:\n",
    "            p1 = np.bincount(temp1_chrom[np.where(np.logical_and(temp1_chrom >= i-outlen//2, temp1_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p1 = np.pad(p1,[0,outlen-len(p1)])\n",
    "            p2 = np.bincount(temp2_chrom[np.where(np.logical_and(temp2_chrom >= i-outlen//2, temp2_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p2 = np.pad(p2,[0,outlen-len(p2)])\n",
    "            p3 = np.bincount(temp3_chrom[np.where(np.logical_and(temp3_chrom >= i-outlen//2, temp3_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p3 = np.pad(p3,[0,outlen-len(p3)])\n",
    "            p_b6.append(p1+p3/2)\n",
    "            p_cast.append(p2+p3/2)\n",
    "        p[rep+'_chr'+str(c)+'_b6'] += p_b6\n",
    "        p[rep+'_chr'+str(c)+'_ca'] += p_cast\n",
    "\n",
    "        p_b6 = []\n",
    "        p_cast = []\n",
    "        for i in neg_summits[c]:    # neg_summits already assigned from seq computation\n",
    "            p1 = np.bincount(temp1_chrom[np.where(np.logical_and(temp1_chrom >= i-outlen//2, temp1_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p1 = np.pad(p1,[0,outlen-len(p1)])\n",
    "            p2 = np.bincount(temp2_chrom[np.where(np.logical_and(temp2_chrom >= i-outlen//2, temp2_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p2 = np.pad(p2,[0,outlen-len(p2)])\n",
    "            p3 = np.bincount(temp3_chrom[np.where(np.logical_and(temp3_chrom >= i-outlen//2, temp3_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p3 = np.pad(p3,[0,outlen-len(p3)])\n",
    "            p_b6.append(p1+p3/2)\n",
    "            p_cast.append(p2+p3/2)\n",
    "        p[rep+'_chr'+str(c)+'_b6_unegs'] += p_b6\n",
    "        p[rep+'_chr'+str(c)+'_ca_unegs'] += p_cast\n",
    "\n",
    "        p_b6 = []\n",
    "        p_cast = []\n",
    "        for i in augsummits:    # neg_summits already assigned from seq computation\n",
    "            p1 = np.bincount(temp1_chrom[np.where(np.logical_and(temp1_chrom >= i-outlen//2, temp1_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p1 = np.pad(p1,[0,outlen-len(p1)])\n",
    "            p2 = np.bincount(temp2_chrom[np.where(np.logical_and(temp2_chrom >= i-outlen//2, temp2_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p2 = np.pad(p2,[0,outlen-len(p2)])\n",
    "            p3 = np.bincount(temp3_chrom[np.where(np.logical_and(temp3_chrom >= i-outlen//2, temp3_chrom < i+outlen//2))[0]] - (i-outlen//2))\n",
    "            p3 = np.pad(p3,[0,outlen-len(p3)])\n",
    "            p_b6.append(p1+p3/2)\n",
    "            p_cast.append(p2+p3/2)\n",
    "        p[rep+'_chr'+str(c)+'_b6_aug'] += p_b6\n",
    "        p[rep+'_chr'+str(c)+'_ca_aug'] += p_cast\n",
    "    \n",
    "    if cnt==0:\n",
    "        bamf.close()\n",
    "        gen_b6.close()\n",
    "        gen_cast.close()\n",
    "    \n",
    "    del p_b6, p_cast, p1, p2, p3, chromsummits, augsummits, temp1, temp2, temp3, cast_shifts, seq_b6, seq_cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "499949dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x's are ready\n",
    "# p's need to be pooled\n",
    "\n",
    "# pool across reps\n",
    "for c in chroms:\n",
    "    for allele in ['b6','ca']:\n",
    "            for label in ['','_unegs','_aug']:\n",
    "                p['chr'+str(c)+'_'+allele+label] = np.zeros_like(p[rep+'_chr'+str(c)+'_'+allele+label])\n",
    "                for i,rep in enumerate(reps):\n",
    "                    p['chr'+str(c)+'_'+allele+label] += np.array(p[rep+'_chr'+str(c)+'_'+allele+label])\n",
    "                    del p[rep+'_chr'+str(c)+'_'+allele+label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dec3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, save everything\n",
    "if save:\n",
    "    with h5py.File(datadir+'data'+ident+'.h5','w') as f:\n",
    "        for key in x.keys():\n",
    "            f.create_dataset('x_'+key, data=x[key])\n",
    "        for key in p.keys():\n",
    "            f.create_dataset('p_'+key, data=p[key])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
